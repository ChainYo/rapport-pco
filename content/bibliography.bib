@misc{temporal_fusion,
  doi = {10.48550/ARXIV.1912.09363},
  url = {https://arxiv.org/abs/1912.09363},
  author = {Lim, Bryan and Arik, Sercan O. and Loeff, Nicolas and Pfister, Tomas},
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{medium_temporal_fusion, 
  url={https://towardsdatascience.com/temporal-fusion-transformer-googles-model-for-interpretable-time-series-forecasting-5aa17beb621}, 
  journal={Temporal Fusion Transformer: Time Series Forecasting with Interpretability}, 
  author={Kafritsas, Nikos}, 
  year={2021}, 
  month={Nov}
}

@article{fund_rnn,
	doi = {10.1016/j.physd.2019.132306},
	url = {https://arxiv.org/abs/1808.03314},
	year = 2020,
	month = {mar},
	publisher = {Elsevier {BV}},
	volume = {404},
	pages = {132306},
	author = {Alex Sherstinsky},
	title = {Fundamentals of Recurrent Neural Network ({RNN}) and Long Short-Term Memory ({LSTM}) network},
	journal = {Physica D: Nonlinear Phenomena}
}

@misc{stanford_rnn, 
  title={Recurrent neural networks cheatsheet star}, 
  url={https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks}, 
  journal={CS 230 - Recurrent Neural Networks Cheatsheet}, 
  publisher={Stanford.edu}, 
  author={Amidi , Afshine and Amidi, Shervine}, 
  year={2020}, 
  month={May}
}

@misc{tp_timeseries, 
  title={TP-timeseries Novembre 2018}, 
  url={https://rchailan.github.io/assets/lectures/timeseries/tp_timeseries.html}, 
  journal={rchailan.github.io}, 
  author={ Chailan, Romain and Palacios-Rodr√≠guez, F.}, 
  year={2018}
}

@misc{goude_2020, 
  title={Les Processus Arima}, 
  url={https://www.imo.universite-paris-saclay.fr/~goude/Materials/time_series/cours6_ARIMA.pdf}, 
  publisher={Paris-Saclay}, 
  author={ Goude, Yannig}, 
  year={2020}
}

@misc{attention_is_all_you_need,
  doi = {10.48550/ARXIV.1706.03762},
  url = {https://arxiv.org/abs/1706.03762},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Attention Is All You Need},
  publisher = {arXiv},
  year = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{bert,
  doi = {10.48550/ARXIV.1810.04805},
  url = {https://arxiv.org/abs/1810.04805},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{gpt2, 
  url={https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf}, 
  journal={Language models are unsupervised multitask learners}, 
  publisher={OpenAI}, 
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya}, 
  year={2019}, 
  month={Feb}
}

@misc{t5,
  doi = {10.48550/ARXIV.1910.10683},
  url = {https://arxiv.org/abs/1910.10683},
  author = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J.},
  keywords = {Machine Learning (cs.LG), Computation and Language (cs.CL), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
 