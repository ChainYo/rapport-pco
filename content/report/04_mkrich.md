\newpage
# Make Us Rich

Il existe beaucoup de ressources, notamment sur les mod√®les de pr√©diction appliqu√©s √† des s√©ries temporelles, qui sont
tr√®s utiles sur des donn√©es stationnaires telles que les donn√©es m√©t√©orologiques ou les vols d'avions. En revanche, en 
ce qui concerne les march√©s financiers et les crypto-monnaies, il est difficile de trouver des m√©thodes dites *classiques*
qui soient aussi efficaces et fiables.

√âtant passionn√© par le *Deep Learning* et surveillant d'un oeil positif l'√©volution des crypto-monnaies, j'ai souhait√©
cr√©er un outil permettant de lier les deux. En plus de cr√©er cet outil de pr√©diction, j'ai voulu aller plus loin et 
d√©velopper le projet pour en faire une base solide √† d√©ployer pour quiconque souhaiterait comprendre les enjeux du 
d√©ploiement de mod√®les de *Deep Learning* et les outils d'automatisation et de supervision des mod√®les.

C'est donc avant tout un projet de passion√©, mais aussi un formidable outil (en tous cas je l'esp√®re) pour apprendre √†
automatiser, d√©ployer et mettre √† disposition des mod√®les de *Deep Learning*. Sans plus attendre, je vous invite √† 
d√©couvrir plus en d√©tails le projet et son architecture pr√©sent√©e en introduction de ce dossier.

Pour conserver une certaine lisibilit√©, les diff√©rents blocs de code sont num√©rot√©s entre paranth√®ses et leur d√©tails 
sont disponibles dans les annexes de ce rapport.

## Les donn√©es

La r√©cup√©ration de donn√©es et la cr√©ation d'un jeu de donn√©es est la premi√®re √©tape d'un projet de *Machine Learning*, 
voir m√™me de *Data Science* en g√©n√©ral. C'est une √©tape qui n'est pas √† sous-estimer, car elle va d√©terminer la r√©ussite 
de votre projet.

### R√©cup√©ration des donn√©es

Cette √©tape de r√©cup√©ration des s√©ries temporelles correspond √† l'√©tape de *fetching* sur le sch√©ma pr√©sent√© en introduction.
Les donn√©es que j'utilise sont des donn√©es publiques collect√©es par beaucoup de plateformes de march√©s financiers. Pour
ce projet, j'ai choisi de r√©cup√©rer les donn√©es de la plateforme *Binance*. *Binance* est une plateforme tr√®s connue dans
le monde de l'√©change de crypto-monnaies et elle dispose d'une API de trading qui permet de r√©cup√©rer des donn√©es tr√®s 
simplement et rapidement. Il suffit de disposer d'un compte sur *Binance* et de se g√©n√©rer un token d'acc√®s pour pouvoir
utiliser cette API de fa√ßon permanente et sans frais.

*Binance* dispose √©galement d'un package Python (`python-binance`) qui facilite les appels √† son API. J'ai donc coder une classe, `BinanceClient`[(1)],
qui permet de g√©rer les interactions avec l'API de *Binance* et qui inclut des m√©thodes telles que la r√©cup√©ration de donn√©es
sur cinq jours, un an ou une p√©riode √† d√©finir par l'utilisateur. Ces m√©thodes requi√®rent en argument un symbole de crypto-
monnaie et une monnaie de comparaison dans tous les cas et renvoient les donn√©es sous forme de `pandas.DataFrame`.

[(1)]: #annexe-1

### Description des donn√©es

Les donn√©es r√©cup√©r√©es sont des s√©ries temporelles de la crypto-monnaie cible compar√©e √† une monnaie. Par exemple, je peux
r√©cup√©rer les donn√©es de la crypto-monnaie *BTC* par rapport √† la monnaie *EUR* sur les 5 derni√®res jours avec un intervalle
de 1 heure. 

On compte 12 colonnes de donn√©es :

* `timestamp` : date et heure de la s√©rie temporelle.
* `open` : valeur d'ouverture de la crypto-monnaie cible sur l'intervalle.
* `high` : valeur haute de la crypto-monnaie cible sur l'intervalle.
* `low` : valeur basse de la crypto-monnaie cible sur l'intervalle.
* `close` : valeur de cl√¥ture de la crypto-monnaie cible sur l'intervalle.
* `volume` : volume d'√©change de la crypto-monnaie cible sur l'intervalle.
* `close_time` : date et heure de la cl√¥ture de la crypto-monnaie cible sur l'intervalle.
* `quote_av` (quote asset volume) : correspond au volume d'√©change de la monnaie cible sur l'intervalle.
* `trades` : correspond au nombre de trades effectu√©s sur l'intervalle.
* `tb_base_av` (taker buy base asset volume) : correspond au volume d'acheteur de la crypto-monnaie cible sur l'intervalle.
* `tb_quote_av` (taker buy quote asset volume) : correspond au volume d'acheteur de la monnaie cible sur l'intervalle.
* `ignore` : correspond √† une colonne qui ne sera pas utilis√©e.

Ce sont des informations classiques que l'on retrouve souvent sur les plateformes de march√©s financiers. Nous allons voir
que pour notre cas d'usage, toutes ces donn√©es ne seront pas utilis√©es. De plus, ces donn√©es ne seront pas stock√©es 
puisqu'elles ne sont plus valables apr√®s la fin de l'intervalle de r√©cup√©ration et que le projet pr√©voit un r√©-entrainement
toutes les heures des mod√®les. Ainsi nous n'avons pas besoin de stocker les donn√©es pour une utilisation ult√©rieure, un 
simple appel √† l'API suffit pour r√©cup√©rer les nouvelles donn√©es utiles √† un entra√Ænement de mod√®le.

### Pr√©paration des donn√©es

Il est n√©cessaire de pr√©parer les donn√©es pour qu'elles soient utilisables par le mod√®le. Pour cela, nous allons utiliser
plusieurs fonctions d√©finies dans l'√©tape de `preprocessing` de ce projet. C'est √† cette √©tape qu'intervient un choix des
*features* √† utiliser pour l'entra√Ænement du mod√®le et leur *engineering*. Le terme *feature engineering* est un terme 
d√©signant les diff√©rentes √©tapes de *raffinage* des donn√©es pour qu'elles soient utilisables par le mod√®le.

#### Extraction des donn√©es utiles

Tout d'abord, nous allons extraire les donn√©es utiles √† partir de la s√©rie temporelle gr√¢ce √† la fonction 
`extract_features_from_dataset()`[(2)]. Pour cela, nous allons utiliser uniquement les colonnes `open`, `high`, `low`, `close` 
et `timestamp`. Nous stockons √©galement la diff√©rence entre la valeur de cl√¥ture et la valeur d'ouverture pour chaque 
intervalle sous le nom `close_change`.

Ainsi √† l'issu de cette √©tape, nous obtenons un nouveau `pandas.DataFrame` qui contient les features sp√©cialement
s√©lectionn√©es pour l'entra√Ænement. Nous n'incluons pas les colonnes relatives aux volumes d'√©change et aux trades, car
c'est la pr√©diction de la valeur de cl√¥ture sur l'intervalle suivant qui nous int√©resse ici. Il serait n√©anmoins possible
d'inclure les notions de volumes dans l'entra√Ænement, mais cela complexifierait le mod√®le et l'alourdirait pour un gain
potentiel √† d√©terminer.

[(2)]: #annexe-2

#### S√©paration des jeux de donn√©es

Une fois nos *features* s√©lectionn√©es, nous allons s√©parer les donn√©es en trois jeux de donn√©es distincts gr√¢ce √† la 
fonction `split_data()`[(3)]. La s√©paration consiste √† diviser les donn√©es en deux jeux de donn√©es : 

* `training_set` : 90%
* `test_set` : 10%

Pour des donn√©es temporelles il est important de ne pas m√©langer la chronologie des donn√©es puisque cela peut cr√©er des 
probl√®mes de coh√©rence. En effet, nous voulons que le mod√®le puisse pr√©dire les valeurs de cl√¥ture sur l'intervalle suivant 
et non pas sur des intervalles pass√©s.

[(3)]: #annexe-3

#### Mise √† l'√©chelle des donn√©es

Il est important de mettre √† l'√©chelle les donn√©es pour que le mod√®le puisse les utiliser correctement. Pour cela, nous
allons utiliser la fonction `scale_data()`[(4)]. Cette fonction va permettre de normaliser les donn√©es pour qu'elles soient
comprises entre -1 et 1 pour nos deux jeux de donn√©es. C'est une technique de normalisation qui permet de r√©duire
les √©carts entre les donn√©es et ainsi les rendre plus facile √† manipuler par le mod√®le lors de l'entra√Ænement.

On utilise ici la m√©thode de normalisation `MinMaxScaler` de la librairie `sklearn`. Il est important de noter que nous
sauvegardons √©galement cet objet de normalisation dans un fichier pickle pour pouvoir l'utiliser plus tard lors de
l'inf√©rence via l'API. En effet, puisque le mod√®le est entra√Æn√© sur des donn√©es normalis√©es, il est primordial qu'elles 
le soient √©galement lors des pr√©dictions post√©rieures. De plus, nous avons besoin de cet objet pour pouvoir inverser la
normalisation des donn√©es pr√©dites et obtenir des valeurs de cl√¥ture r√©elles, c'est-√†-dire des valeurs de cl√¥ture non
normalis√©es.

[(4)]: #annexe-4

#### Pr√©paration des s√©quences de donn√©es

Il ne reste plus qu'√† pr√©parer les donn√©es pour qu'elles soient utilisables par le mod√®le. Pour cela, nous allons devoir
cr√©er des s√©quences de donn√©es. Pour cela, nous allons utiliser la fonction `create_sequences()`[(5)]. Cette fonction va
utiliser les donn√©es pr√©alablement normalis√©es pour cr√©er des s√©quences de donn√©es de taille `sequence_length`.

C'est √† cette √©tape que nous construisons les *features* d'entr√©e du mod√®le et la *target* de sortie, aussi appel√© *label*.
Dans notre cas, nous utiliserons la colonne `close` comme *target* et le reste des colonnes comme *features*.

Il est √† noter que nous allons s√©parer les donn√©es du `training_set` en deux s√©quences de donn√©es distinctes pour avoir
√©galement des s√©quences de donn√©es pour la validation du mod√®le, gr√¢ce √† la fonction `split_train_and_val_sequences()`[(6)]. 
Nous utiliserons comme taille `val_size=0.2` pour la validation du mod√®le, ce qui repr√©sente 18% des donn√©es totales 
attribu√©es pour la validation du mod√®le.

[(5)]: #annexe-5
[(6)]: #annexe-6

## Mod√©lisation

Pour ce projet, nous avons choisi d'utiliser un mod√®le de type *LSTM* pour pr√©dire les valeurs de cl√¥ture de la monnaie
sur un intervalle de temps de 1 heure. Pour le chargement des donn√©es, la d√©finition de l'architecture du mod√®le ainsi
que son entra√Ænement, nous avons choisi d'utiliser la librairie [*PyTorch-Lightning*](https://pytorchlightning.ai/) qui 
est une sur-couche de l'excellente librairie *PyTorch*. Cette librairie permet de packager plus simplement et rapidement 
du code *PyTorch*, ce qui va nous aider pour le d√©ploiement et le service de nos mod√®les via notre API dans un second temps.

### D√©finition de l'architecture du mod√®le

Nous allons commencer par d√©crire l'architecture du mod√®le qui se compose de deux parties compl√©mentaires :

* Un premier module `LSTMRegressor`[(7)] qui d√©finit la structure du mod√®le, les hyperparam√®tres, ainsi que les diff√©rentes
√©tapes d'inf√©rence via un `nn.Module` de *PyTorch*.
* Un second module `PricePredictor`[(8)] qui h√©rite de l'architecture du premier module et qui va permettre de d√©finir
les √©tapes d'entra√Ænement, de validation, de test, le *learning rate* et la fonction de *loss* du mod√®le.

La fonction de *loss* du mod√®le est la fonction de co√ªt qui va permettre de d√©terminer la qualit√© du mod√®le. Nous utilisons
la fonction de co√ªt `nn.MSELoss()` de la librairie *PyTorch* qui va nous permettre de calculer l'erreur au carr√© (*mean
squared error*, en anglais) entre la valeur pr√©dite et la valeur r√©elle.

Pour l'entra√Ænement du mod√®le, nous utiliserons un *dataloader* qui va permettre de charger les donn√©es en batchs. C'est
la classe `LSTMDataLoader`[(9)] qui h√©rite de `CryptoDataset`[(10)] qui va s'occuper de charger et de distribuer les
batchs de donn√©es lors des diff√©rentes phases d'entra√Ænement, validation et test.

[(7)]: #annexe-7
[(8)]: #annexe-8
[(9)]: #annexe-9
[(10)]: #annexe-10

### Choix des hyperparam√®tres

Les hyperparam√®tres utilis√©s pour l'entra√Ænement de notre mod√®le ne sont pas d√©finis dans le code, mais dans un fichier
de configuration √† part. Cela permet de faciliter la modification des hyperparam√®tres du mod√®le et de faciliter le
re-entra√Ænement du mod√®le si besoin. Ils sont donc d√©finis dans un fichier `/conf/base/parameters.yaml` o√π se trouvent
√©galement les param√®tres de *fetching* et *preprocessing* des donn√©es. 

Ce fonctionnement est important puisqu'il permet d'harmoniser le d√©roulement du pipeline complet. Ainsi, nous n'avons plus
besoin de toucher aux fichiers de code pour tester des nouveaux hyperparam√®tres, de m√™me si nous voulons augmenter la 
taille des s√©quences de donn√©es.

Voici la liste des hyperparam√®tres retenus et utilis√©s pour l'entra√Ænement des mod√®les :

```yml
training:
  train_batch_size: 64
  val_batch_size: 1
  train_workers: 2
  val_workers: 1
  max_epochs: 100
  hidden_size: 128
  number_of_features: 9
  number_of_layers: 2
  dropout_rate: 0.2
  learning_rate: 1e-4
  log_n_steps: 2
  run_on_gpu: True # False if running on CPU
  wandb_project: "make-us-rich"
```

### Entra√Ænements et monitoring

L'entra√Ænement du mod√®le se fait via la m√©thode `training_loop()`[(11)] qui instancie les classes : `LSTMDataLoader`, 
`PricePredictor` utilis√©es par `Trainer` qui est la classe `Trainer` de *PyTorch-Lightning* qui g√®re l'entra√Ænement.

Nous utilisons une *seed* pour figer l'al√©atoire du mod√®le, via la fonction `seed_everything` de la librairie 
*PyTorch-Lightning*, afin de pouvoir reproduire les r√©sultats du mod√®le si besoin. Nous d√©finissons √©galement deux
*callbacks* :

* `ModelCheckpoint()` qui va permettre de sauvegarder les poids du mod√®le √† chaque *epoch* et de conserver uniquement
    les poids les plus performants.
* `EarlyStopping()` qui va permettre de stopper l'entra√Ænement du mod√®le si le mod√®le n'a pas progress√© depuis un certain
    nombre d'*epochs*. Ici, nous utilisons un *patience* de 2 *epochs*.

Dans les deux cas, nous utilisons les valeurs de *loss* de validation, que l'on cherche √† minimiser, pour d√©terminer les
poids les plus performants et s'il faut continuer ou stopper l'entra√Ænement.

En ce qui concerne le *monitoring* et le *logging*, nous utilisons la classe `WandbLogger` de *Wandb* incluse dans la
librairie *PyTorch-Lightning* qui va nous permettre de stocker les hyperparam√®tres, l'environnement et toutes les m√©triques
de notre mod√®le directement sur *Wandb*.

*Wandb* est un outil de monitoring qui permet de stocker l'historique des entra√Ænements de nos mod√®les et de comparer les
diff√©rents mod√®les. C'est cette plateforme que nous avons privil√©gi√© pour l'exp√©rimentation et le monitoring de nos mod√®les.
J'ai donc cr√©√© un projet sur *Wandb* pour *Make-Us-Rich* et connect√© le pipeline d'entra√Ænement pour que tout soit stock√©
directement sur *Wandb*[(12)].

[(11)]: #annexe-11
[(12)]: #annexe-12

### Validation du mod√®le

La validation du mod√®le se fait en v√©rifiant que la moyenne de la valeur de *loss* de validation et celle de test est bien
inf√©rieure √† une certaine valeur. Cette partie est assez l√©g√®re et m√©riterait un ajustement dans notre pipeline d'entra√Ænement
automatique. L'architecture du mod√®le permet n√©anmoins d'obtenir des r√©sultats satisfaisants qui sont directement observables
et comparables sur l'interface de *Wandb*. 

On peut constater tout de m√™me que le taux d'erreur sur les donn√©es de validation est vraiment tr√®s faible, et il est 
meilleur que le taux d'erreur sur les donn√©es de test. En effet, plus on s'√©loigne dans le temps des donn√©es d'entra√Ænement,
et plus la pr√©cision du mod√®le diminue et donc plus le taux d'erreur, la *loss*, augmente.

### Conversion vers ONNX

Nous avons fait le choix d'inclure une √©tape de conversion automatique du mod√®le en *ONNX* afin de faciliter la prise en
charge de ce mod√®le par d'autres applications et √©galement un optimisation du temps d'inf√©rence lors du service des mod√®les
via *API*.

En effet le format *ONNX* (*Open Neural Network Exchange*) est un format de repr√©sentation de mod√®le standardis√© qui permet, 
notamment sur *CPU*, de r√©duire les temps de calcul des mod√®les [@chaigneau_2022]. C'est via deux fonctions que nous allons 
pouvoir convertir le mod√®le en *ONNX* et valider que le mod√®le converti est conforme au mod√®le original, surtout au 
niveau de la pr√©cision des pr√©dictions. 

La premi√®re fonction `convert_model()`[(13)] permet la conversion du mod√®le en *ONNX* et son stockage avant validation. 
La seconde fonction `validate_model()`[(14)] assure que le mod√®le converti est valable d'un point de vue architecture et 
noeuds des graphiques, ainsi qu'au niveau de la pr√©cision par rapport au mod√®le *PyTorch* original. La diff√©rence entre 
les deux pr√©dictions doit respecter une tol√©rance absolue de $10^{-5}$ et une tol√©rance relative de $10^{-3}$.

[(13)]: #annexe-13
[(14)]: #annexe-14

### Stockage des mod√®les et des features engineering

Il ne nous reste plus qu'√† stocker les mod√®les et les features engineering dans une base de donn√©es. Vu les donn√©es que
nous souhaitons conserver, c'est une base de donn√©es orient√©e vers le stockage objet que nous utiliserons, tel que *AWS S3*,
*Google Cloud Storage* ou *Azure Blob Storage*. Dans notre cas, nous utilisons *Minio* pour stocker nos donn√©es, car c'est
l'√©quivalent de *AWS S3* mais h√©bergeable n'importe o√π sur le web ou en local.

C'est gr√¢ce √† la fonction `upload_files()`[(15)] que nous allons pouvoir stocker nos mod√®les et les features engineering qui
sont associ√©es dans un r√©pertoire unique de notre base de donn√©es. Ainsi, ils seront accessibles par la suite par l'API
pour leur utilisation.

Enfin, afin de s'assurer que les fichiers g√©n√©r√©s par l'entra√Ænement d'un mod√®le et permettre de conserver de l'espace 
disque sur la machine qui r√©alise l'entra√Ænement, nous utilisons une fonction de nettoyage de tous les fichiers locaux 
qui ne sont plus utilis√©s. Ceci est r√©alis√© par la derni√®re fonction du pipeline nomm√©e `clean_files()`[(16)].

[(15)]: #annexe-15

## Service des mod√®les

...

### Qu'est-ce-que servir des mod√®les

...

### üê≥ Docker

...

### Pr√©sentation de l'API

...

#### Gestion des mod√®les

...

#### Les endpoints de l'API

...

## Interface utilisateur

TODO :
- pr√©sentation de l'interface utilisateur
- base de donn√©es relationnelle pour authentification
- tokens pour appels API

## Packaging du projet

TODO :
- ETL - Prefect
- D√©ploiement - Docker, Cloud ou Local
- Documentation - Mkdocs material
- Alerting

